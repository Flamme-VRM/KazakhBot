import asyncio
import os

from aiogram import Bot, Dispatcher
from aiogram.filters import Command
from aiogram.types import Message
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv(".env")

BOT_TOKEN = os.getenv("BOT_TOKEN")

LLM_API_KEY = os.getenv("LLM_API_KEY")

genai.configure(api_key=LLM_API_KEY)
model = genai.GenerativeModel(os.getenv("MODEL"))

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

user_history = {}

async def get_ai_response(user_id: int, text: str) -> str:
    try:
        if user_id not in user_history:
            user_history[user_id] = []

        user_history[user_id].append(f'User: {text}')
        recent_history = user_history[user_id][-10:]
        full_prompt = "\n\nConversation History: \n" + "\n".join(recent_history)

        response = model.generate_content(full_prompt)
        user_history[user_id].append(f"AlatauLLM: {response.text}")

        return response.text
    except Exception as e:
        return "–ö–µ—à—ñ—Ä—ñ“£—ñ–∑, “õ–∞–∑—ñ—Ä –∂–∞—É–∞–ø –±–µ—Ä–µ –∞–ª–º–∞–π–º—ã–Ω"

@dp.message(Command("start"))
async def start_command(message: Message):
    greeting = """üá∞üáø –°”ô–ª–µ–º–µ—Ç—Å—ñ–∑ –±–µ! AlatauLLM'“ì–∞ “õ–æ—à –∫–µ–ª–¥—ñ“£—ñ–∑!

–ú–µ–Ω —Å—ñ–∑–±–µ–Ω “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ —Å”©–π–ª–µ—Å–µ –∞–ª–∞—Ç—ã–Ω –ò–ò –±–æ—Å–ø–∞–Ω—ã–º—ã–Ω. –ú–∞“ì–∞–Ω –∫–µ–∑ –∫–µ–ª–≥–µ–Ω —Å“±—Ä–∞“õ “õ–æ—è –∞–ª–∞—Å—ã–∑:

üìù –ú”ô—Ç—ñ–Ω –∂–∞–∑—É –∂”ô–Ω–µ –∞—É–¥–∞—Ä—É
üí¨ “ö–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ —Å“±—Ö–±–∞—Ç
üìö –ë—ñ–ª—ñ–º –±–µ—Ä—É —Å“±—Ä–∞“õ—Ç–∞—Ä—ã  
üéØ –ñ–∞–ª–ø—ã –∫”©–º–µ–∫

–•–∞–±–∞—Ä–ª–∞–º–∞ –∂—ñ–±–µ—Ä—ñ–ø, –±–∞—Å—Ç–∞–π—ã“õ! üí´"""
    await message.answer(greeting, parse_mode='Markdown')
    
    
@dp.message()
async def echo(message: Message):
    ai_response = await get_ai_response(message.from_user.id, message.text)
    await message.answer(ai_response, parse_mode='Markdown')


async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
